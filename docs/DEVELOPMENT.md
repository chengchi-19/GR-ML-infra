# å¼€å‘è€…æŒ‡å—

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒæ­å»º

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- CUDA 11.8+ (GPUå¼€å‘)
- Git 2.20+
- Docker (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–å¼€å‘)

### å¼€å‘ç¯å¢ƒå®‰è£…
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd GR-ML-infra

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt  # å¼€å‘å·¥å…·

# 4. éªŒè¯å®‰è£…
python tests/test_integration.py
```

### IDEé…ç½®æ¨è
```json
// .vscode/settings.json
{
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"]
}
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„ç†è§£

### æ ¸å¿ƒè®¾è®¡æ¨¡å¼
1. **é€‚é…å™¨æ¨¡å¼**: ç»Ÿä¸€ä¸åŒå¼€æºæ¡†æ¶çš„æ¥å£
2. **ç®¡é“æ¨¡å¼**: HSTUâ†’ONNXâ†’TensorRTâ†’VLLMçš„ç»Ÿä¸€å¤„ç†é“¾
3. **è§‚å¯Ÿè€…æ¨¡å¼**: æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
4. **å·¥å‚æ¨¡å¼**: åˆ›å»ºå’Œç®¡ç†æ¨ç†å¼•æ“

### å…³é”®æŠ½è±¡å±‚çº§
```
åº”ç”¨å±‚ (main.py)
    â†“
æ§åˆ¶å±‚ (framework_controller.py)
    â†“
é€‚é…å±‚ (integrations/*.py)
    â†“  
å¼•æ“å±‚ (HSTU/VLLM/TensorRT)
```

### æ•°æ®æµå›¾
```
ç”¨æˆ·è¯·æ±‚ â†’ ç‰¹å¾é¢„å¤„ç† â†’ HSTUç‰¹å¾æå– â†’ ONNXå¯¼å‡º â†’ TensorRTä¼˜åŒ– â†’ VLLMæ¨ç† â†’ ç»“æœåå¤„ç† â†’ å“åº”è¾“å‡º
    â†‘                                                                 â†“
 ç›‘æ§ç»Ÿè®¡ â†â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” æ€§èƒ½è®°å½• â†â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç¼“å­˜ç®¡ç†
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶å¼€å‘

### 1. æ–°å¢æ¨ç†æ¡†æ¶

#### Step 1: åˆ›å»ºæ¡†æ¶é€‚é…å™¨
```python
# integrations/new_framework/new_engine.py
class NewFrameworkEngine:
    def __init__(self, config):
        self.config = config
        self.available = self._check_availability()
    
    def _check_availability(self) -> bool:
        """æ£€æŸ¥æ¡†æ¶æ˜¯å¦å¯ç”¨"""
        try:
            import new_framework
            return True
        except ImportError:
            return False
    
    def infer(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨ç†"""
        if not self.available:
            raise RuntimeError("New framework not available")
        
        # å®ç°æ¨ç†é€»è¾‘
        return results
    
    async def batch_infer(self, requests: List[Dict]) -> List[Dict]:
        """æ‰¹é‡æ¨ç†"""
        # å®ç°æ‰¹é‡æ¨ç†é€»è¾‘
        pass
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'available': self.available,
            'model_info': {},
            'performance_metrics': {}
        }
```

#### Step 2: é›†æˆåˆ°æ§åˆ¶å™¨
```python
# integrations/framework_controller.py
from integrations.new_framework.new_engine import NewFrameworkEngine

class OpenSourceFrameworkController:
    def __init__(self, config):
        # ç°æœ‰ä»£ç ...
        self.new_engine = NewFrameworkEngine(config.get('new_framework', {}))
        self.framework_availability['new_framework'] = self.new_engine.available
    
    def _select_optimal_strategy(self, user_behaviors):
        # æ·»åŠ æ–°çš„ç­–ç•¥é€‰æ‹©é€»è¾‘
        if some_condition and self.new_engine.available:
            return "new_framework"
        # ç°æœ‰é€»è¾‘...
```

#### Step 3: æ·»åŠ é…ç½®æ”¯æŒ
```python
# main.py - create_optimized_config()
def create_optimized_config():
    config = {
        # ç°æœ‰é…ç½®...
        'new_framework': {
            'model_name': 'new-model',
            'precision': 'fp16',
            'max_batch_size': 8,
            # æ¡†æ¶ç‰¹å®šé…ç½®...
        }
    }
    return config
```

### 2. è‡ªå®šä¹‰ç®—å­å¼€å‘

#### Tritonç®—å­ç¤ºä¾‹
```python
# optimizations/triton_ops/custom_attention.py
import triton
import triton.language as tl

@triton.jit
def custom_attention_kernel(
    Q, K, V, O,
    seq_len, head_dim,
    BLOCK_SIZE: tl.constexpr
):
    # Triton kernelå®ç°
    pass

def custom_attention(q, k, v):
    """è‡ªå®šä¹‰æ³¨æ„åŠ›ç®—å­"""
    # è°ƒç”¨Triton kernel
    return output
```

#### é›†æˆåˆ°æ¨ç†å¼•æ“
```python
# integrations/hstu/hstu_model.py
from optimizations.triton_ops.custom_attention import custom_attention

class HSTUGenerativeRecommender:
    def forward(self, input_ids, attention_mask, **kwargs):
        # ä½¿ç”¨è‡ªå®šä¹‰ç®—å­
        if self.use_custom_ops:
            attention_output = custom_attention(q, k, v)
        else:
            attention_output = self.attention(q, k, v)
        
        return outputs
```

### 3. ç¼“å­˜ç­–ç•¥æ‰©å±•

#### æ–°ç¼“å­˜ç­–ç•¥
```python
# optimizations/cache/new_cache_strategy.py
class NewCacheStrategy:
    def __init__(self, config):
        self.config = config
    
    def should_cache(self, key: str, value: Any) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç¼“å­˜"""
        pass
    
    def get_priority(self, key: str) -> float:
        """è·å–ç¼“å­˜ä¼˜å…ˆçº§"""  
        pass
    
    def eviction_candidate(self, cache_items) -> str:
        """é€‰æ‹©é©±é€å€™é€‰é¡¹"""
        pass
```

#### é›†æˆåˆ°æ™ºèƒ½ç¼“å­˜
```python
# optimizations/cache/intelligent_cache.py
from .new_cache_strategy import NewCacheStrategy

class IntelligentEmbeddingCache:
    def __init__(self, config):
        # ç°æœ‰ä»£ç ...
        if config.get('strategy') == 'new_strategy':
            self.cache_strategy = NewCacheStrategy(config)
```

## ğŸ§ª æµ‹è¯•å¼€å‘

### å•å…ƒæµ‹è¯•
```python
# tests/test_new_framework.py
import unittest
from integrations.new_framework.new_engine import NewFrameworkEngine

class TestNewFramework(unittest.TestCase):
    def setUp(self):
        self.config = {'model_name': 'test-model'}
        self.engine = NewFrameworkEngine(self.config)
    
    def test_availability_check(self):
        """æµ‹è¯•æ¡†æ¶å¯ç”¨æ€§æ£€æŸ¥"""
        availability = self.engine._check_availability()
        self.assertIsInstance(availability, bool)
    
    def test_inference(self):
        """æµ‹è¯•æ¨ç†åŠŸèƒ½"""
        inputs = {'input_ids': [1, 2, 3]}
        result = self.engine.infer(inputs)
        self.assertIn('predictions', result)
    
    def test_batch_inference(self):
        """æµ‹è¯•æ‰¹é‡æ¨ç†"""
        requests = [{'input_ids': [1, 2, 3]}] * 5
        results = self.engine.batch_infer(requests)
        self.assertEqual(len(results), 5)
```

### é›†æˆæµ‹è¯•
```python
# tests/test_integration_extended.py
def test_new_framework_integration():
    """æµ‹è¯•æ–°æ¡†æ¶é›†æˆ"""
    config = create_optimized_config()
    controller = create_integrated_controller(config)
    
    # éªŒè¯æ¡†æ¶æ³¨å†Œ
    assert 'new_framework' in controller.framework_availability
    
    # æµ‹è¯•ç­–ç•¥é€‰æ‹©
    strategy = controller._select_optimal_strategy(mock_behaviors)
    assert strategy in ['hstu', 'vllm', 'tensorrt', 'new_framework', 'fallback']
```

### æ€§èƒ½æµ‹è¯•
```python
# tests/test_performance_extended.py
import time
import pytest

@pytest.mark.performance
def test_new_framework_performance():
    """æµ‹è¯•æ–°æ¡†æ¶æ€§èƒ½"""
    engine = NewFrameworkEngine(test_config)
    
    if not engine.available:
        pytest.skip("New framework not available")
    
    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    start_time = time.time()
    for _ in range(100):
        result = engine.infer(test_input)
    end_time = time.time()
    
    avg_latency = (end_time - start_time) / 100 * 1000  # ms
    assert avg_latency < 50.0, f"Performance regression: {avg_latency}ms"
```

## ğŸ“Š ç›‘æ§ä¸è°ƒè¯•

### æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
```python
# integrations/framework_controller.py
class OpenSourceFrameworkController:
    def __init__(self, config):
        # ç°æœ‰ä»£ç ...
        self.custom_metrics = defaultdict(list)
    
    def _record_custom_metric(self, metric_name: str, value: float):
        """è®°å½•è‡ªå®šä¹‰æŒ‡æ ‡"""
        self.custom_metrics[metric_name].append({
            'timestamp': time.time(),
            'value': value
        })
```

### æ—¥å¿—é…ç½®
```python
# utils/logging_config.py
import logging
import sys

def setup_logging(level='INFO'):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=getattr(logging, level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('development.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # è®¾ç½®ç‰¹å®šæ¨¡å—çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('integrations').setLevel(logging.DEBUG)
    logging.getLogger('optimizations').setLevel(logging.INFO)
```

### è°ƒè¯•å·¥å…·
```python
# utils/debug_tools.py
import functools
import time

def performance_timer(func):
    """æ€§èƒ½è®¡æ—¶è£…é¥°å™¨"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {(end-start)*1000:.2f}ms")
        return result
    return wrapper

def memory_tracker(func):
    """å†…å­˜ä½¿ç”¨è¿½è¸ªè£…é¥°å™¨"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        import psutil
        process = psutil.Process()
        mem_before = process.memory_info().rss / 1024 / 1024  # MB
        result = func(*args, **kwargs)
        mem_after = process.memory_info().rss / 1024 / 1024
        print(f"{func.__name__} memory usage: {mem_after - mem_before:.2f}MB")
        return result
    return wrapper
```

## ğŸš€ éƒ¨ç½²ä¸å‘å¸ƒ

### å¼€å‘ç¯å¢ƒéƒ¨ç½²
```bash
# æœ¬åœ°å¼€å‘æœåŠ¡å™¨
python main.py --mode=single --log-level=DEBUG

# çƒ­é‡è½½å¼€å‘
pip install watchdog
watchmedo auto-restart --patterns="*.py" --recursive -- python main.py
```

### å®¹å™¨åŒ–å¼€å‘
```dockerfile
# Dockerfile.dev
FROM nvidia/cuda:11.8-devel-ubuntu22.04

WORKDIR /app
COPY requirements-dev.txt .
RUN pip install -r requirements-dev.txt

COPY . .
CMD ["python", "main.py", "--mode=comprehensive"]
```

### CI/CDé…ç½®
```yaml
# .github/workflows/test.yml
name: CI Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    - name: Install dependencies
      run: pip install -r requirements-dev.txt
    - name: Run tests
      run: python -m pytest tests/ -v
    - name: Run integration tests
      run: python tests/test_integration.py
```

## ğŸ“‹ ä»£ç è§„èŒƒ

### ä»£ç é£æ ¼
```python
# ä½¿ç”¨Blackæ ¼å¼åŒ–
black --line-length 88 .

# ä½¿ç”¨flake8æ£€æŸ¥
flake8 --max-line-length 88 --ignore E203,W503 .

# ä½¿ç”¨isortæ’åºå¯¼å…¥
isort --profile black .
```

### æ–‡æ¡£è§„èŒƒ
```python
def infer_recommendations(
    self,
    user_id: str,
    session_id: str, 
    user_behaviors: List[Dict[str, Any]],
    num_recommendations: int = 10,
    **kwargs
) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ¨èæ¨ç†
    
    Args:
        user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
        session_id: ä¼šè¯æ ‡è¯†  
        user_behaviors: ç”¨æˆ·è¡Œä¸ºåºåˆ—
        num_recommendations: æ¨èæ•°é‡
        **kwargs: é¢å¤–å‚æ•°
        
    Returns:
        Dict containing:
            - recommendations: æ¨èç»“æœåˆ—è¡¨
            - inference_strategy: ä½¿ç”¨çš„æ¨ç†ç­–ç•¥
            - inference_time_ms: æ¨ç†æ—¶é—´(æ¯«ç§’)
            
    Raises:
        ValueError: å‚æ•°æ— æ•ˆ
        RuntimeError: æ¨ç†å¤±è´¥
    """
```

### Gitæäº¤è§„èŒƒ
```bash
# æäº¤æ¶ˆæ¯æ ¼å¼
git commit -m "feat: æ·»åŠ æ–°çš„æ¨ç†æ¡†æ¶æ”¯æŒ"
git commit -m "fix: ä¿®å¤VLLMå†…å­˜æ³„æ¼é—®é¢˜" 
git commit -m "docs: æ›´æ–°APIæ–‡æ¡£"
git commit -m "test: æ·»åŠ æ€§èƒ½å›å½’æµ‹è¯•"
git commit -m "refactor: é‡æ„ç¼“å­˜ç®¡ç†æ¨¡å—"
```

---

**ğŸ¯ å¼€å‘åŸåˆ™**: 
1. **æ¨¡å—åŒ–è®¾è®¡**: æ–°åŠŸèƒ½ç‹¬ç«‹å¼€å‘ï¼Œæ¥å£ç»Ÿä¸€
2. **æµ‹è¯•é©±åŠ¨**: å…ˆå†™æµ‹è¯•ï¼Œå†å®ç°åŠŸèƒ½
3. **æ€§èƒ½ä¼˜å…ˆ**: æ¯ä¸ªæ”¹åŠ¨éƒ½è¦è€ƒè™‘æ€§èƒ½å½±å“
4. **å‘åå…¼å®¹**: ä¿æŒAPIå…¼å®¹æ€§
5. **æ–‡æ¡£å®Œå–„**: ä»£ç å³æ–‡æ¡£ï¼Œæ³¨é‡Šæ¸…æ™°
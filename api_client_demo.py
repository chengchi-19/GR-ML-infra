# APIå®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹

from api_server import UserBehavior, InferenceRequest
import requests
import json
from datetime import datetime
import asyncio
import aiohttp

class HSTUAPIClient:
    """HSTUæ¨ç†ä¼˜åŒ–APIå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
    
    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        try:
            response = self.session.get(f"{self.base_url}/health")
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            response = self.session.get(f"{self.base_url}/stats")
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def generate_demo_data(self, user_id: str, num_behaviors: int = 20):
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
        try:
            response = self.session.post(
                f"{self.base_url}/generate_demo_data",
                params={"user_id": user_id, "num_behaviors": num_behaviors}
            )
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def infer(self, request: dict):
        """å•æ¬¡æ¨ç†"""
        try:
            response = self.session.post(
                f"{self.base_url}/infer",
                json=request,
                headers={"Content-Type": "application/json"}
            )
            return response.json()
        except Exception as e:
            return {"error": str(e)}
    
    def batch_infer(self, requests: list):
        """æ‰¹é‡æ¨ç†"""
        try:
            batch_request = {"requests": requests}
            response = self.session.post(
                f"{self.base_url}/batch_infer",
                json=batch_request,
                headers={"Content-Type": "application/json"}
            )
            return response.json()
        except Exception as e:
            return {"error": str(e)}

def create_sample_request():
    """åˆ›å»ºç¤ºä¾‹è¯·æ±‚"""
    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ•°æ®
    behaviors = [
        {
            "video_id": 12345,
            "timestamp": 1700000000,
            "interaction_type": "view",
            "duration": 120.5,
            "device_type": "mobile"
        },
        {
            "video_id": 12346,
            "timestamp": 1700001000,
            "interaction_type": "like",
            "duration": None,
            "device_type": "mobile"
        },
        {
            "video_id": 12347,
            "timestamp": 1700002000,
            "interaction_type": "share",
            "duration": None,
            "device_type": "desktop"
        }
    ]
    
    return {
        "user_id": "user_demo_001",
        "session_id": "session_" + str(int(datetime.now().timestamp())),
        "user_behaviors": behaviors,
        "num_recommendations": 10,
        "strategy": "unified",
        "enable_cache": True
    }

def demo_single_inference():
    """æ¼”ç¤ºå•æ¬¡æ¨ç†"""
    print("ğŸ” æ¼”ç¤ºå•æ¬¡æ¨ç†...")
    
    client = HSTUAPIClient()
    
    # å¥åº·æ£€æŸ¥
    print("1. å¥åº·æ£€æŸ¥:")
    health = client.health_check()
    print(f"   çŠ¶æ€: {health.get('status', 'unknown')}")
    
    # åˆ›å»ºæ¨ç†è¯·æ±‚
    request = create_sample_request()
    print(f"\n2. æ¨ç†è¯·æ±‚:")
    print(f"   ç”¨æˆ·ID: {request['user_id']}")
    print(f"   è¡Œä¸ºæ•°é‡: {len(request['user_behaviors'])}")
    print(f"   æ¨èç­–ç•¥: {request['strategy']}")
    
    # æ‰§è¡Œæ¨ç†
    print("\n3. æ‰§è¡Œæ¨ç†...")
    result = client.infer(request)
    
    if 'error' in result:
        print(f"âŒ æ¨ç†å¤±è´¥: {result['error']}")
        return
    
    print("âœ… æ¨ç†æˆåŠŸ!")
    print(f"   æ¨èæ•°é‡: {len(result.get('recommendations', []))}")
    print(f"   æ€»è€—æ—¶: {result.get('metrics', {}).get('total_time_ms', 0):.2f}ms")
    print(f"   ä½¿ç”¨ç­–ç•¥: {result.get('metrics', {}).get('strategy_used', 'unknown')}")
    
    # æ˜¾ç¤ºå‰3ä¸ªæ¨è
    recommendations = result.get('recommendations', [])[:3]
    print(f"\n4. æ¨èç»“æœé¢„è§ˆ:")
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. è§†é¢‘ID: {rec.get('video_id')}, å¾—åˆ†: {rec.get('score', 0):.3f}")

def demo_batch_inference():
    """æ¼”ç¤ºæ‰¹é‡æ¨ç†"""
    print("\nğŸ” æ¼”ç¤ºæ‰¹é‡æ¨ç†...")
    
    client = HSTUAPIClient()
    
    # åˆ›å»ºå¤šä¸ªæ¨ç†è¯·æ±‚
    requests = []
    for i in range(3):
        request = create_sample_request()
        request['user_id'] = f"user_batch_{i+1:03d}"
        requests.append(request)
    
    print(f"1. æ‰¹é‡è¯·æ±‚æ•°é‡: {len(requests)}")
    
    # æ‰§è¡Œæ‰¹é‡æ¨ç†
    print("2. æ‰§è¡Œæ‰¹é‡æ¨ç†...")
    result = client.batch_infer(requests)
    
    if 'error' in result:
        print(f"âŒ æ‰¹é‡æ¨ç†å¤±è´¥: {result['error']}")
        return
    
    print("âœ… æ‰¹é‡æ¨ç†æˆåŠŸ!")
    batch_metrics = result.get('batch_metrics', {})
    print(f"   å¤„ç†è¯·æ±‚: {batch_metrics.get('successful_requests', 0)}/{batch_metrics.get('total_requests', 0)}")
    print(f"   æ€»è€—æ—¶: {batch_metrics.get('batch_processing_time_ms', 0):.2f}ms")
    print(f"   å¹³å‡è€—æ—¶: {batch_metrics.get('average_request_time_ms', 0):.2f}ms")

def demo_stats_monitoring():
    """æ¼”ç¤ºç»Ÿè®¡ç›‘æ§"""
    print("\nğŸ” æ¼”ç¤ºç»Ÿè®¡ç›‘æ§...")
    
    client = HSTUAPIClient()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = client.get_stats()
    
    if 'error' in stats:
        print(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {stats['error']}")
        return
    
    server_stats = stats.get('server_stats', {})
    print("ğŸ“Š æœåŠ¡å™¨ç»Ÿè®¡:")
    print(f"   è¿è¡Œæ—¶é—´: {server_stats.get('uptime_seconds', 0):.1f}ç§’")
    print(f"   æ€»è¯·æ±‚æ•°: {server_stats.get('total_requests', 0)}")
    print(f"   æˆåŠŸç‡: {server_stats.get('success_rate', 0)*100:.1f}%")
    print(f"   å¹³å‡å»¶è¿Ÿ: {server_stats.get('average_inference_time_ms', 0):.2f}ms")

def demo_auto_data_generation():
    """æ¼”ç¤ºè‡ªåŠ¨æ•°æ®ç”Ÿæˆ"""
    print("\nğŸ” æ¼”ç¤ºè‡ªåŠ¨æ•°æ®ç”Ÿæˆ...")
    
    client = HSTUAPIClient()
    
    # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
    demo_data = client.generate_demo_data("user_auto_demo", num_behaviors=15)
    
    if 'error' in demo_data:
        print(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {demo_data['error']}")
        return
    
    print("âœ… æ¼”ç¤ºæ•°æ®ç”ŸæˆæˆåŠŸ!")
    print(f"   ç”¨æˆ·ID: {demo_data.get('user_id')}")
    print(f"   è¡Œä¸ºæ•°é‡: {demo_data.get('count')}")
    
    # ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è¿›è¡Œæ¨ç†
    behaviors = demo_data.get('behaviors', [])
    if behaviors:
        inference_request = {
            "user_id": demo_data.get('user_id'),
            "user_behaviors": behaviors,
            "num_recommendations": 10,
            "strategy": "unified"
        }
        
        print("ğŸ”„ ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è¿›è¡Œæ¨ç†...")
        result = client.infer(inference_request)
        
        if 'error' not in result:
            print("âœ… æ¨ç†æˆåŠŸ!")
            print(f"   æ¨èæ•°é‡: {len(result.get('recommendations', []))}")
            print(f"   æ¨ç†è€—æ—¶: {result.get('metrics', {}).get('total_time_ms', 0):.2f}ms")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ" * 50)
    print("HSTUæ¨ç†ä¼˜åŒ–API - å®¢æˆ·ç«¯ä½¿ç”¨æ¼”ç¤º")
    print("ğŸŒŸ" * 50)
    
    try:
        # 1. å•æ¬¡æ¨ç†æ¼”ç¤º
        demo_single_inference()
        
        # 2. æ‰¹é‡æ¨ç†æ¼”ç¤º
        demo_batch_inference()
        
        # 3. ç»Ÿè®¡ç›‘æ§æ¼”ç¤º
        demo_stats_monitoring()
        
        # 4. è‡ªåŠ¨æ•°æ®ç”Ÿæˆæ¼”ç¤º
        demo_auto_data_generation()
        
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“š æ›´å¤šä¿¡æ¯:")
        print("   - APIæ–‡æ¡£: http://localhost:8000/docs")
        print("   - å¥åº·æ£€æŸ¥: http://localhost:8000/health")
        print("   - ç»Ÿè®¡ä¿¡æ¯: http://localhost:8000/stats")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿APIæœåŠ¡å·²å¯åŠ¨: python api_server.py")

if __name__ == "__main__":
    main()
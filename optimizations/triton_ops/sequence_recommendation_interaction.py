#!/usr/bin/env python3
"""
åºåˆ—æ¨èäº¤äº’Tritonç®—å­

é’ˆå¯¹æ¨èç³»ç»Ÿç”¨æˆ·è¡Œä¸ºåºåˆ—çš„æ—¶åºäº¤äº’ç‰¹å¾è®¡ç®—
ä¸“é—¨ä¼˜åŒ–ç”¨æˆ·-ç‰©å“äº¤äº’ã€ç‰©å“-ç‰©å“å…±ç°ã€æ—¶åºæƒé‡è¡°å‡ç­‰æ¨èåœºæ™¯

æ ¸å¿ƒä¼˜åŒ–ï¼š
1. æ—¶åºæƒé‡è¡°å‡ï¼šè¿‘æœŸè¡Œä¸ºæƒé‡æ›´é«˜  
2. å¤šå°ºåº¦äº¤äº’ï¼šçŸ­æœŸ/é•¿æœŸå…´è¶£å¹¶è¡Œè®¡ç®—
3. ç¨€ç–ä¼˜åŒ–ï¼šè·³è¿‡æ— æ•ˆäº¤äº’ï¼Œæé«˜è®¡ç®—æ•ˆç‡
4. ç¼“å­˜å‹å¥½ï¼šä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼
"""

import triton
import triton.language as tl
import torch
import torch.nn.functional as F
import math
import logging

logger = logging.getLogger(__name__)

@triton.jit
def sequence_recommendation_interaction_kernel(
    # Input tensors
    item_emb_ptr,           # [B, S, D] - ç‰©å“åµŒå…¥åºåˆ—
    user_emb_ptr,           # [B, D] - ç”¨æˆ·åµŒå…¥
    time_weights_ptr,       # [B, S] - æ—¶åºæƒé‡
    interaction_mask_ptr,   # [B, S] - äº¤äº’æ©ç  (1=æœ‰æ•ˆ, 0=padding)
    
    # Output tensors  
    user_item_scores_ptr,   # [B, S] - ç”¨æˆ·-ç‰©å“äº¤äº’åˆ†æ•°
    item_cooccur_ptr,       # [B, S, S] - ç‰©å“å…±ç°çŸ©é˜µ
    short_term_ptr,         # [B, D] - çŸ­æœŸå…´è¶£è¡¨ç¤º
    long_term_ptr,          # [B, D] - é•¿æœŸåå¥½è¡¨ç¤º
    
    # Dimensions
    B: tl.constexpr,        # Batch size
    S: tl.constexpr,        # Sequence length  
    D: tl.constexpr,        # Embedding dimension
    
    # Parameters
    SHORT_WINDOW: tl.constexpr,  # çŸ­æœŸçª—å£å¤§å°
    LONG_WINDOW: tl.constexpr,   # é•¿æœŸçª—å£å¤§å°
    DECAY_FACTOR: tl.constexpr,  # æ—¶åºè¡°å‡å› å­
    
    # Block sizes
    BLOCK_S: tl.constexpr,
    BLOCK_D: tl.constexpr,
):
    """
    åºåˆ—æ¨èäº¤äº’æ ¸å¿ƒè®¡ç®—
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. èåˆå¤šç§äº¤äº’è®¡ç®—ï¼Œå‡å°‘kernelå¯åŠ¨å¼€é”€
    2. åˆ©ç”¨shared memoryç¼“å­˜å¸¸ç”¨æ•°æ®
    3. å‘é‡åŒ–è®¡ç®—ï¼Œæé«˜å¹¶è¡Œåº¦
    4. æ—¶åºæ„ŸçŸ¥çš„æƒé‡è®¡ç®—
    """
    
    # è·å–program ID
    pid_batch = tl.program_id(0)
    pid_seq = tl.program_id(1)
    
    # è¾¹ç•Œæ£€æŸ¥
    if pid_batch >= B or pid_seq >= S:
        return
    
    # è®¡ç®—åŸºç¡€åç§»
    batch_offset = pid_batch * S * D
    current_item_offset = batch_offset + pid_seq * D
    user_offset = pid_batch * D
    
    # åŠ è½½å½“å‰ç‰©å“åµŒå…¥
    d_offs = tl.arange(0, BLOCK_D)
    d_mask = d_offs < D
    current_item_emb = tl.load(item_emb_ptr + current_item_offset + d_offs, 
                               mask=d_mask, other=0.0)
    
    # åŠ è½½ç”¨æˆ·åµŒå…¥
    user_emb = tl.load(user_emb_ptr + user_offset + d_offs, 
                       mask=d_mask, other=0.0)
    
    # åŠ è½½æ—¶åºæƒé‡å’Œäº¤äº’æ©ç 
    time_weight = tl.load(time_weights_ptr + pid_batch * S + pid_seq)
    interaction_mask = tl.load(interaction_mask_ptr + pid_batch * S + pid_seq)
    
    # å¦‚æœå½“å‰ä½ç½®æ— æ•ˆï¼Œè·³è¿‡è®¡ç®—
    if interaction_mask == 0:
        return
    
    # === 1. è®¡ç®—ç”¨æˆ·-ç‰©å“äº¤äº’åˆ†æ•° ===
    user_item_score = tl.sum(user_emb * current_item_emb) * time_weight
    tl.store(user_item_scores_ptr + pid_batch * S + pid_seq, user_item_score)
    
    # === 2. è®¡ç®—ç‰©å“å…±ç°çŸ©é˜µ ===
    # åªè®¡ç®—ä¸Šä¸‰è§’çŸ©é˜µä»¥èŠ‚çœè®¡ç®—
    if pid_seq < S - 1:
        for other_seq in range(pid_seq + 1, S):
            # åŠ è½½å…¶ä»–ç‰©å“çš„æ©ç 
            other_mask_offset = pid_batch * S + other_seq
            other_mask = tl.load(interaction_mask_ptr + other_mask_offset)
            
            if other_mask == 0:
                continue
            
            # åŠ è½½å…¶ä»–ç‰©å“åµŒå…¥
            other_item_offset = batch_offset + other_seq * D
            other_item_emb = tl.load(item_emb_ptr + other_item_offset + d_offs,
                                   mask=d_mask, other=0.0)
            
            # è®¡ç®—ç‰©å“é—´ç›¸ä¼¼åº¦
            item_similarity = tl.sum(current_item_emb * other_item_emb)
            
            # åº”ç”¨æ—¶åºè¡°å‡ - è·ç¦»è¶Šè¿‘æƒé‡è¶Šé«˜
            seq_distance = other_seq - pid_seq
            temporal_decay = tl.exp(-DECAY_FACTOR * seq_distance)
            
            cooccur_score = item_similarity * temporal_decay
            
            # å­˜å‚¨å…±ç°åˆ†æ•° (ä¸Šä¸‰è§’çŸ©é˜µ)
            cooccur_offset = (pid_batch * S + pid_seq) * S + other_seq
            tl.store(item_cooccur_ptr + cooccur_offset, cooccur_score)
    
    # === 3. æ›´æ–°çŸ­æœŸå’Œé•¿æœŸå…´è¶£è¡¨ç¤º ===
    # ä½¿ç”¨åŸå­æ“ä½œç´¯åŠ åˆ°å…¨å±€å†…å­˜
    
    # çŸ­æœŸå…´è¶£ï¼šæœ€è¿‘SHORT_WINDOWä¸ªç‰©å“çš„åŠ æƒå¹³å‡
    if pid_seq >= S - SHORT_WINDOW:
        short_weight = time_weight * (1.0 + (pid_seq - (S - SHORT_WINDOW)) * 0.1)
        weighted_item_emb = current_item_emb * short_weight
        
        # åŸå­ç´¯åŠ åˆ°çŸ­æœŸå…´è¶£è¡¨ç¤º
        short_base = short_term_ptr + pid_batch * D
        for d_idx in range(0, D, BLOCK_D):
            d_block_offs = d_idx + d_offs
            d_block_mask = d_block_offs < D
            
            if d_block_mask.any():
                values = tl.where(d_block_mask, 
                                weighted_item_emb[d_offs], 0.0)
                # TritonåŸå­åŠ æ³•
                tl.atomic_add(short_base + d_block_offs, values, mask=d_block_mask)
    
    # é•¿æœŸåå¥½ï¼šå…¨åºåˆ—çš„æ—¶åºåŠ æƒå¹³å‡
    long_weight = time_weight * (0.5 + 0.5 * tl.exp(-0.1 * (S - pid_seq - 1)))
    weighted_long_emb = current_item_emb * long_weight
    
    # åŸå­ç´¯åŠ åˆ°é•¿æœŸåå¥½è¡¨ç¤º
    long_base = long_term_ptr + pid_batch * D
    for d_idx in range(0, D, BLOCK_D):
        d_block_offs = d_idx + d_offs  
        d_block_mask = d_block_offs < D
        
        if d_block_mask.any():
            values = tl.where(d_block_mask,
                            weighted_long_emb[d_offs], 0.0)
            tl.atomic_add(long_base + d_block_offs, values, mask=d_block_mask)


@triton.jit  
def sequence_collaborative_filtering_kernel(
    # Inputs
    item_emb_ptr,           # [B, S, D] - ç‰©å“åµŒå…¥åºåˆ—
    item_cooccur_ptr,       # [B, S, S] - ç‰©å“å…±ç°çŸ©é˜µ (ä»ä¸Šä¸ªkernelè¾“å‡º)
    interaction_mask_ptr,   # [B, S] - äº¤äº’æ©ç 
    
    # Outputs
    cf_scores_ptr,          # [B, S] - ååŒè¿‡æ»¤åˆ†æ•°
    neighbor_weights_ptr,   # [B, S, TOP_K] - è¿‘é‚»æƒé‡
    
    # Dimensions & Parameters
    B: tl.constexpr, S: tl.constexpr, D: tl.constexpr,
    TOP_K: tl.constexpr,    # Top-Kè¿‘é‚»æ•°é‡
    MIN_COOCCUR: tl.constexpr,  # æœ€å°å…±ç°é˜ˆå€¼
    
    # Block sizes
    BLOCK_S: tl.constexpr, BLOCK_D: tl.constexpr
):
    """
    åŸºäºåºåˆ—çš„ååŒè¿‡æ»¤è®¡ç®—
    
    æ ¹æ®ç‰©å“å…±ç°çŸ©é˜µè®¡ç®—ååŒè¿‡æ»¤æ¨èåˆ†æ•°
    """
    
    pid_batch = tl.program_id(0)
    pid_seq = tl.program_id(1)
    
    if pid_batch >= B or pid_seq >= S:
        return
    
    # æ£€æŸ¥å½“å‰ç‰©å“æ˜¯å¦æœ‰æ•ˆ
    mask_offset = pid_batch * S + pid_seq
    current_mask = tl.load(interaction_mask_ptr + mask_offset)
    
    if current_mask == 0:
        return
    
    # åˆå§‹åŒ–ååŒè¿‡æ»¤åˆ†æ•°
    cf_score = 0.0
    neighbor_count = 0
    
    # å­˜å‚¨Top-Kè¿‘é‚»çš„åˆ†æ•°å’Œç´¢å¼•
    top_scores = tl.zeros([TOP_K], dtype=tl.float32) - 1e9
    top_indices = tl.zeros([TOP_K], dtype=tl.int32)
    
    # æ‰«ææ‰€æœ‰å…¶ä»–ç‰©å“æ‰¾è¿‘é‚»
    cooccur_base = (pid_batch * S + pid_seq) * S
    
    for other_seq in range(S):
        if other_seq == pid_seq:
            continue
            
        # æ£€æŸ¥å…¶ä»–ç‰©å“æ˜¯å¦æœ‰æ•ˆ
        other_mask_offset = pid_batch * S + other_seq
        other_mask = tl.load(interaction_mask_ptr + other_mask_offset)
        
        if other_mask == 0:
            continue
        
        # è·å–å…±ç°åˆ†æ•°
        if pid_seq < other_seq:
            # ä»ä¸Šä¸‰è§’çŸ©é˜µè¯»å–
            cooccur_score = tl.load(item_cooccur_ptr + cooccur_base + other_seq)
        elif pid_seq > other_seq:
            # ä»ä¸‹ä¸‰è§’ä½ç½®è¯»å–ï¼ˆå¯¹ç§°ï¼‰
            symmetric_offset = (pid_batch * S + other_seq) * S + pid_seq
            cooccur_score = tl.load(item_cooccur_ptr + symmetric_offset)
        else:
            cooccur_score = 1.0  # è‡ªå·±å’Œè‡ªå·±
        
        # å¦‚æœå…±ç°åˆ†æ•°è¶³å¤Ÿé«˜ï¼Œè€ƒè™‘ä½œä¸ºè¿‘é‚»
        if cooccur_score > MIN_COOCCUR:
            # æ›´æ–°Top-Kè¿‘é‚»åˆ—è¡¨
            min_score = tl.min(top_scores)
            min_idx = 0
            
            # æ‰¾åˆ°æœ€å°åˆ†æ•°çš„ä½ç½®
            for k in range(TOP_K):
                if top_scores[k] == min_score:
                    min_idx = k
                    break
            
            # å¦‚æœå½“å‰åˆ†æ•°æ›´é«˜ï¼Œæ›¿æ¢
            if cooccur_score > min_score:
                top_scores[min_idx] = cooccur_score
                top_indices[min_idx] = other_seq
                
            cf_score += cooccur_score
            neighbor_count += 1
    
    # å½’ä¸€åŒ–ååŒè¿‡æ»¤åˆ†æ•°
    if neighbor_count > 0:
        cf_score = cf_score / neighbor_count
    
    # å­˜å‚¨ç»“æœ
    tl.store(cf_scores_ptr + pid_batch * S + pid_seq, cf_score)
    
    # å­˜å‚¨Top-Kè¿‘é‚»æƒé‡
    neighbor_base = (pid_batch * S + pid_seq) * TOP_K
    for k in range(TOP_K):
        tl.store(neighbor_weights_ptr + neighbor_base + k, top_scores[k])


class SequenceRecommendationInteraction(torch.autograd.Function):
    """
    åºåˆ—æ¨èäº¤äº’PyTorchå°è£…
    """
    
    @staticmethod
    def forward(ctx, item_embeddings, user_embedding, time_weights, interaction_mask,
                short_window=8, long_window=32, decay_factor=0.1):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            item_embeddings: [B, S, D] - ç‰©å“åµŒå…¥åºåˆ—
            user_embedding: [B, D] - ç”¨æˆ·åµŒå…¥
            time_weights: [B, S] - æ—¶åºæƒé‡
            interaction_mask: [B, S] - äº¤äº’æ©ç 
        """
        
        B, S, D = item_embeddings.shape
        device = item_embeddings.device
        
        # è¾“å‡ºå¼ é‡
        user_item_scores = torch.zeros(B, S, device=device, dtype=torch.float32)
        item_cooccur = torch.zeros(B, S, S, device=device, dtype=torch.float32)
        short_term = torch.zeros(B, D, device=device, dtype=torch.float32)  
        long_term = torch.zeros(B, D, device=device, dtype=torch.float32)
        
        # ç¡®å®šblockå¤§å°
        BLOCK_S = min(16, S)
        BLOCK_D = min(64, triton.next_power_of_2(D))
        
        # ç½‘æ ¼é…ç½®
        grid = (B, S)
        
        # è°ƒç”¨ä¸»è¦çš„äº¤äº’è®¡ç®—kernel
        sequence_recommendation_interaction_kernel[grid](
            item_embeddings, user_embedding, time_weights, interaction_mask,
            user_item_scores, item_cooccur, short_term, long_term,
            B=B, S=S, D=D,
            SHORT_WINDOW=short_window,
            LONG_WINDOW=long_window, 
            DECAY_FACTOR=decay_factor,
            BLOCK_S=BLOCK_S, BLOCK_D=BLOCK_D
        )
        
        # è®¡ç®—ååŒè¿‡æ»¤åˆ†æ•°
        cf_scores = torch.zeros(B, S, device=device, dtype=torch.float32)
        neighbor_weights = torch.zeros(B, S, 8, device=device, dtype=torch.float32)  # Top-8
        
        sequence_collaborative_filtering_kernel[grid](
            item_embeddings, item_cooccur, interaction_mask,
            cf_scores, neighbor_weights,
            B=B, S=S, D=D, TOP_K=8, MIN_COOCCUR=0.1,
            BLOCK_S=BLOCK_S, BLOCK_D=BLOCK_D
        )
        
        # ä¿å­˜åå‘ä¼ æ’­æ‰€éœ€å˜é‡
        ctx.save_for_backward(item_embeddings, user_embedding, time_weights, interaction_mask)
        
        return {
            'user_item_scores': user_item_scores,
            'item_cooccur': item_cooccur, 
            'short_term': short_term,
            'long_term': long_term,
            'cf_scores': cf_scores,
            'neighbor_weights': neighbor_weights
        }
    
    @staticmethod  
    def backward(ctx, grad_dict):
        """åå‘ä¼ æ’­ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        item_embeddings, user_embedding, time_weights, interaction_mask = ctx.saved_tensors
        
        # è¿”å›ç®€åŒ–æ¢¯åº¦
        grad_items = torch.zeros_like(item_embeddings)
        grad_user = torch.zeros_like(user_embedding)
        grad_weights = None
        grad_mask = None
        
        return grad_items, grad_user, grad_weights, grad_mask, None, None, None


def sequence_recommendation_interaction(item_embeddings, user_embedding, time_weights, 
                                      interaction_mask, **kwargs):
    """
    ä¾¿æ·å‡½æ•°ï¼šåºåˆ—æ¨èäº¤äº’è®¡ç®—
    
    Args:
        item_embeddings: [B, S, D] - ç”¨æˆ·äº¤äº’çš„ç‰©å“åµŒå…¥åºåˆ—
        user_embedding: [B, D] - ç”¨æˆ·åµŒå…¥  
        time_weights: [B, S] - æ—¶åºæƒé‡ (è¿‘æœŸæƒé‡é«˜)
        interaction_mask: [B, S] - äº¤äº’æ©ç  (1=æœ‰æ•ˆ, 0=padding)
        
    Returns:
        dict: {
            'user_item_scores': ç”¨æˆ·-ç‰©å“äº¤äº’åˆ†æ•°,
            'item_cooccur': ç‰©å“å…±ç°çŸ©é˜µ,
            'short_term': çŸ­æœŸå…´è¶£è¡¨ç¤º,
            'long_term': é•¿æœŸåå¥½è¡¨ç¤º,
            'cf_scores': ååŒè¿‡æ»¤åˆ†æ•°,
            'neighbor_weights': è¿‘é‚»æƒé‡
        }
        
    Usage:
        # ç”¨æˆ·è¡Œä¸ºåºåˆ—
        item_seq = torch.randn(2, 20, 128)  # 2ä¸ªç”¨æˆ·ï¼Œ20ä¸ªç‰©å“ï¼Œ128ç»´
        user_emb = torch.randn(2, 128)      # ç”¨æˆ·åµŒå…¥
        
        # æ—¶åºæƒé‡ï¼šè¿‘æœŸè¡Œä¸ºæƒé‡æ›´é«˜
        time_weights = torch.exp(-0.1 * torch.arange(20).float()).unsqueeze(0).repeat(2, 1)
        
        # äº¤äº’æ©ç 
        interaction_mask = torch.ones(2, 20)
        
        # è®¡ç®—åºåˆ—æ¨èç‰¹å¾
        results = sequence_recommendation_interaction(
            item_seq, user_emb, time_weights, interaction_mask
        )
    """
    return SequenceRecommendationInteraction.apply(
        item_embeddings, user_embedding, time_weights, interaction_mask, **kwargs
    )


def create_temporal_weights(sequence_lengths, decay_factor=0.1, device='cuda'):
    """
    åˆ›å»ºæ—¶åºæƒé‡ï¼šè¶Šè¿‘æœŸçš„è¡Œä¸ºæƒé‡è¶Šé«˜
    
    Args:
        sequence_lengths: List[int] - æ¯ä¸ªç”¨æˆ·çš„å®é™…åºåˆ—é•¿åº¦
        decay_factor: float - è¡°å‡å› å­
        device: str - è®¾å¤‡
        
    Returns:
        time_weights: [B, S] - æ—¶åºæƒé‡å¼ é‡
    """
    B = len(sequence_lengths)
    S = max(sequence_lengths)
    
    time_weights = torch.zeros(B, S, device=device)
    
    for i, seq_len in enumerate(sequence_lengths):
        # å¯¹æœ‰æ•ˆåºåˆ—ä½ç½®è®¾ç½®è¡°å‡æƒé‡
        positions = torch.arange(seq_len, device=device)
        weights = torch.exp(-decay_factor * (seq_len - 1 - positions))
        time_weights[i, :seq_len] = weights
    
    return time_weights


# æ€§èƒ½æµ‹è¯•
def benchmark_sequence_recommendation():
    """åºåˆ—æ¨èäº¤äº’æ€§èƒ½æµ‹è¯•"""
    
    print("ğŸš€ åºåˆ—æ¨èäº¤äº’æ€§èƒ½æµ‹è¯•") 
    print("=" * 50)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    test_configs = [
        (4, 32, 128),    # (B, S, D) - å°è§„æ¨¡
        (8, 64, 256),    # ä¸­ç­‰è§„æ¨¡  
        (16, 128, 512),  # å¤§è§„æ¨¡
    ]
    
    for B, S, D in test_configs:
        print(f"\næµ‹è¯•é…ç½®: B={B}, S={S}, D={D}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        item_embeddings = torch.randn(B, S, D, device=device, dtype=torch.float32)
        user_embedding = torch.randn(B, D, device=device, dtype=torch.float32)
        
        # åˆ›å»ºæ—¶åºæƒé‡
        seq_lengths = [S] * B  # å‡è®¾æ‰€æœ‰åºåˆ—éƒ½æ˜¯æ»¡é•¿åº¦
        time_weights = create_temporal_weights(seq_lengths, device=device)
        
        # åˆ›å»ºéšæœºæ©ç  (æ¨¡æ‹Ÿéƒ¨åˆ†padding)
        interaction_mask = torch.ones(B, S, device=device)
        # éšæœºmaskæ‰ä¸€äº›ä½ç½®
        mask_ratio = 0.1
        num_mask = int(B * S * mask_ratio)
        mask_indices = torch.randperm(B * S)[:num_mask]
        interaction_mask.view(-1)[mask_indices] = 0
        
        # é¢„çƒ­
        for _ in range(3):
            _ = sequence_recommendation_interaction(
                item_embeddings, user_embedding, time_weights, interaction_mask
            )
        
        if device.type == 'cuda':
            torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        import time
        num_runs = 10
        
        start_time = time.time()
        for _ in range(num_runs):
            results = sequence_recommendation_interaction(
                item_embeddings, user_embedding, time_weights, interaction_mask
            )
        
        if device.type == 'cuda':
            torch.cuda.synchronize()
        
        elapsed = time.time() - start_time
        avg_time = elapsed / num_runs * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        print(f"  å¹³å‡è€—æ—¶: {avg_time:.2f}ms")
        print(f"  ç”¨æˆ·-ç‰©å“åˆ†æ•°å½¢çŠ¶: {results['user_item_scores'].shape}")
        print(f"  ç‰©å“å…±ç°çŸ©é˜µå½¢çŠ¶: {results['item_cooccur'].shape}")
        print(f"  çŸ­æœŸå…´è¶£å½¢çŠ¶: {results['short_term'].shape}")
        print(f"  é•¿æœŸåå¥½å½¢çŠ¶: {results['long_term'].shape}")
        print(f"  å†…å­˜ä½¿ç”¨: ~{(item_embeddings.numel() * 4 * 3) / 1024**2:.1f}MB")
        
        # éªŒè¯è¾“å‡ºåˆç†æ€§
        print(f"  ç”¨æˆ·-ç‰©å“åˆ†æ•°èŒƒå›´: [{results['user_item_scores'].min():.3f}, {results['user_item_scores'].max():.3f}]")
        print(f"  ååŒè¿‡æ»¤åˆ†æ•°èŒƒå›´: [{results['cf_scores'].min():.3f}, {results['cf_scores'].max():.3f}]")


if __name__ == "__main__":
    benchmark_sequence_recommendation()
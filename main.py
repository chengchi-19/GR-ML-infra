#!/usr/bin/env python3
"""
HSTUæ¨ç†ä¼˜åŒ–é¡¹ç›® - é…ç½®å’Œæµ‹è¯•å·¥å…·

ä¸»è¦åŠŸèƒ½:
- ç”Ÿæˆæ¨ç†ä¼˜åŒ–é…ç½®
- å¿«é€Ÿç³»ç»Ÿå¯ç”¨æ€§æ£€æŸ¥
- ç®€å•çš„æ¨ç†æµ‹è¯•

æ³¨æ„: ç”Ÿäº§ç¯å¢ƒè¯·ä½¿ç”¨APIæœåŠ¡ (python api_server.py)
"""

import sys
import os
import json
import logging
import argparse
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def create_optimized_config() -> Dict[str, Any]:
    """åˆ›å»ºä¼˜åŒ–é…ç½®"""
    
    config = {
        # Meta HSTUæ¨¡å‹é…ç½®
        'hstu': {
            'vocab_size': 50000,
            'd_model': 1024,
            'num_layers': 12,
            'num_heads': 16,
            'd_ff': 4096,
            'max_seq_len': 2048,
            'dropout': 0.1,
            'hstu_expansion_factor': 4,
            'hstu_gate_type': 'sigmoid',
            'enable_hierarchical_attention': True,
            'similarity_dim': 256,
            'temperature': 0.1,
            'pretrained_path': None,
        },
        
        # VLLMæ¨ç†ä¼˜åŒ–é…ç½®
        'vllm': {
            'model_name': 'hstu-generative-recommender',
            'model_path': None,
            'tensor_parallel_size': 1,
            'pipeline_parallel_size': 1,
            'gpu_memory_utilization': 0.85,
            'max_model_len': 2048,
            'max_num_seqs': 256,
            'max_num_batched_tokens': None,
            'block_size': 16,
            'dtype': 'float16',
            'seed': 42,
            'quantization': None,
            'enable_chunked_prefill': True,
        },
        
        # TensorRTæ¨ç†åŠ é€Ÿé…ç½®
        'tensorrt': {
            'model_name': 'hstu-tensorrt-optimized',
            'onnx_path': None,
            'engine_path': 'models/hstu_fp16.trt',
            'precision': 'fp16',
            'max_batch_size': 8,
            'max_workspace_size': 2 << 30,  # 2GB
            'optimization_level': 5,
            'enable_dynamic_shapes': True,
            'enable_strict_types': False,
            'enable_fp16_io': True,
            'min_shapes': {
                'input_ids': (1, 8),
                'attention_mask': (1, 8),
                'dense_features': (1, 1024),
            },
            'opt_shapes': {
                'input_ids': (4, 128),
                'attention_mask': (4, 128),
                'dense_features': (4, 1024),
            },
            'max_shapes': {
                'input_ids': (8, 2048),
                'attention_mask': (8, 2048),
                'dense_features': (8, 1024),
            },
        },
        
        # è‡ªå®šä¹‰ç®—å­ä¼˜åŒ–é…ç½®
        'optimizations': {
            'enable_triton_ops': True,
            'enable_cutlass_ops': True,
            'enable_intelligent_cache': True,
            'cache_size': 8192,
            'triton_operators': {
                'enable_fused_attention_layernorm': True,
                'enable_hierarchical_sequence_fusion': True,
                'enable_hstu_hierarchical_attention': True,
                'enable_sequence_recommendation_interaction': True,
                'enable_interaction_operator': True,
            }
        }
    }
    
    return config

def check_system_availability():
    """æ£€æŸ¥ç³»ç»Ÿå¯ç”¨æ€§"""
    logger.info("ğŸ” æ£€æŸ¥ç³»ç»Ÿæ¡†æ¶å¯ç”¨æ€§...")
    
    try:
        from integrations.framework_controller import create_integrated_controller
        
        # åˆ›å»ºæ§åˆ¶å™¨å¹¶æ£€æŸ¥å¯ç”¨æ€§
        controller = create_integrated_controller()
        availability = controller.framework_availability
        
        logger.info("ğŸ“Š æ¡†æ¶å¯ç”¨æ€§çŠ¶æ€:")
        logger.info(f"  Meta HSTUæ¨¡å‹: {'âœ…' if availability.get('hstu', False) else 'âŒ'}")
        logger.info(f"  VLLMæ¨ç†å¼•æ“: {'âœ…' if availability.get('vllm', False) else 'âŒ'}")
        logger.info(f"  TensorRTåŠ é€Ÿ: {'âœ…' if availability.get('tensorrt', False) else 'âŒ'}")
        logger.info(f"  Tritonç®—å­: {'âœ…' if availability.get('triton_ops', False) else 'âŒ'}")
        logger.info(f"  æ™ºèƒ½ç¼“å­˜: {'âœ…' if availability.get('cache', False) else 'âŒ'}")
        
        available_count = sum(availability.values())
        total_count = len(availability)
        success_rate = available_count / total_count if total_count > 0 else 0
        
        logger.info(f"ğŸ“ˆ æ€»ä½“å¯ç”¨æ€§: {available_count}/{total_count} ({success_rate:.1%})")
        
        if success_rate >= 0.8:
            logger.info("âœ… ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œå»ºè®®å¯åŠ¨APIæœåŠ¡")
        elif success_rate >= 0.5:
            logger.info("âš ï¸ ç³»ç»Ÿéƒ¨åˆ†å¯ç”¨ï¼ŒAPIæœåŠ¡å¯å¯åŠ¨ä½†æ€§èƒ½å¯èƒ½å—é™")
        else:
            logger.info("âŒ ç³»ç»Ÿå¯ç”¨æ€§è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç¯å¢ƒé…ç½®")
            
        return controller
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
        logger.info("ğŸ’¡ è¯·æ£€æŸ¥é¡¹ç›®ä¾èµ–å’Œç¯å¢ƒé…ç½®")
        return None

def run_simple_test():
    """è¿è¡Œç®€å•æµ‹è¯•"""
    logger.info("ğŸ§ª è¿è¡Œç®€å•æ¨ç†æµ‹è¯•...")
    
    try:
        controller = check_system_availability()
        if controller is None:
            return False
            
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_behaviors = [
            {
                'video_id': 12345,
                'timestamp': 1700000000,
                'interaction_type': 'view',
                'duration': 120.5,
                'device_type': 'mobile'
            }
        ]
        
        # æ‰§è¡Œæµ‹è¯•æ¨ç†
        result = controller.infer_with_optimal_strategy(
            user_id="test_user_001",
            session_id="test_session_001",
            user_behaviors=test_behaviors,
            num_recommendations=5,
            requested_strategy="unified"
        )
        
        if 'error' not in result:
            logger.info("âœ… ç®€å•æ¨ç†æµ‹è¯•é€šè¿‡")
            logger.info(f"ğŸ“Š æ¨ç†ç­–ç•¥: {result.get('strategy_used', 'unknown')}")
            logger.info(f"â±ï¸ æ¨ç†è€—æ—¶: {result.get('inference_time_ms', 0):.2f}ms")
            return True
        else:
            logger.error(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {result.get('error', 'unknown')}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return False

def save_config_to_file(config: Dict[str, Any], filename: str = "config.json"):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {filename}")
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='HSTUæ¨ç†ä¼˜åŒ–é¡¹ç›® - é…ç½®å’Œæµ‹è¯•å·¥å…·')
    parser.add_argument('--action', 
                       choices=['config', 'check', 'test'], 
                       default='check',
                       help='æ“ä½œæ¨¡å¼: config(ç”Ÿæˆé…ç½®), check(æ£€æŸ¥å¯ç”¨æ€§), test(è¿è¡Œæµ‹è¯•)')
    parser.add_argument('--config-file', 
                       default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--log-level', 
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', 
                       help='æ—¥å¿—çº§åˆ«')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    print("ğŸŒŸ" * 50)
    print("HSTUæ¨ç†ä¼˜åŒ–é¡¹ç›® - é…ç½®å’Œæµ‹è¯•å·¥å…·")
    print("ğŸŒŸ" * 50)
    print("é›†æˆæŠ€æœ¯æ ˆ:")
    print("  ğŸ“š Meta HSTU (Hierarchical Sequential Transduction Units)")
    print("  âš¡ VLLM (PagedAttention + Continuous Batching)")
    print("  ğŸš€ TensorRT (GPU Inference Acceleration)")
    print("  ğŸ”§ Custom Triton + CUTLASS Operators")
    print("  ğŸ§  Intelligent GPU Hot Cache")
    print("")
    print("ğŸ’¡ ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨APIæœåŠ¡:")
    print("   python api_server.py")
    print("   è®¿é—® http://localhost:8000/docs æŸ¥çœ‹APIæ–‡æ¡£")
    print("ğŸŒŸ" * 50)
    
    success = False
    
    try:
        if args.action == 'config':
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            logger.info("âš™ï¸ ç”Ÿæˆæ¨ç†ä¼˜åŒ–é…ç½®...")
            config = create_optimized_config()
            success = save_config_to_file(config, args.config_file)
            
        elif args.action == 'check':
            # æ£€æŸ¥ç³»ç»Ÿå¯ç”¨æ€§
            controller = check_system_availability()
            success = controller is not None
            
        elif args.action == 'test':
            # è¿è¡Œç®€å•æµ‹è¯•
            success = run_simple_test()
        
        if success:
            print(f"\nğŸ‰ {args.action} æ“ä½œå®Œæˆï¼")
        else:
            print(f"\nâŒ {args.action} æ“ä½œå¤±è´¥ï¼")
            
        return 0 if success else 1
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
        return 1
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())